```
-- Andrew Ng 교수님의 Neural Networks and Deep Learning 강의의 1주차 강의를 듣고 필기한 내용입니다.
-- 강의는 코세라와 Edwith에서 들었으며, 코딩 과제 자료는 코세라에서 보고 따라갔습니다.
```



## 3. Shallow Neural Networks

**Gradient Descent For Neural Networks** 

- 단일층 신경망에서 경사 하강법을 구현하기 위한 방법은 다음과 같습니다.

- -  `dw1` $= \frac {dJ}{\delta w^{[1]}}$
  -  `db1` $= \frac {\delta J}{\delta b^{[1]}}$ 
  -  $W^{[1]} = W^{[1]} - \alpha dW^{[1]}$
  -  $b^{[1]} = b^{[1]}- \alpha db^{[1]}

- 단일층이 아닐 때는 1뿐만 아니라 1, 2, …,m 까지의 계산을 반복하면 됩니다.

- - 