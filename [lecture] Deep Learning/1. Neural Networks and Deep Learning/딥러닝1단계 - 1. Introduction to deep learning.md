```
-- Andrew Ng 교수님의 Neural Networks and Deep Learning 강의의 1주차 강의를 듣고 필기한 내용입니다.
-- 강의는 코세라와 Edwith에서 들었으며, 코딩 과제 자료는 코세라에서 보고 따라갔습니다.
```

## 1. Introduction to deep learning

### 1.1. 코스 소개

#### 이번 과정에서 배울 내용은? 

- 뉴럴 네트워크 & 딥러닝
- 딥뉴럴네트워크 성능을 개선하는 방법: 하이퍼파라미터 튜닝, 규제, 최적화 등
- 머신러닝 프로젝트를 구조화하는 방법
- CNN
- 자연어 처리 :  sequence model을 만드는 방법



### 1.2. What is a neural network

#### Housing Price Prediction

- 뉴런은 입력값 `x` 를 `y` 값으로 매칭해줌(예: relu함수)

- 뉴런 여러개가 쌓이면 **neural network** 가 되는 것

- 충분한 데이터를 주면 x와 y를 연결하는 신경망의 성능은 더 좋아질 것!

  

### 1.3. Supervised Learning with a Neural Network

#### Supervised lerning applications

- standart NN : real estate house price prediction , online advertising click on ad problem, etc...
- CNN : Photo tagging
- RNN : Speech recognition, translation,  ... (sequential data)
- Hybrid : autonomous driving

#### Structured Data vs Unstructured data

- 신경망은 비구조화 데이터(사진, 음성, 텍스트 등)을 컴퓨터가 인식하는 데 많은 발전을 가져다줌 
- 돈이 되는 예측은 구조화 데이터를 다루는 예측이 많긴 함
- 이번 강의에선 두 가지 데이터 모두 다를 예정
- 어쨋든 신경망은 supervised learning을 많이 발전시킴

### 1.4. Why is deep learning taking off?

#### Data 양의 증가

- 전통적인 머신러닝 알고리즘은 데이터 양이 증가함에 따라 모델 성능이 어느정도 늘어나지만, 어느 순간 데이터 양의 증가한다고 해서 성능이 더 개선되진 않음
- 스마트 기기의 보급으로 점점 더 많은 양의 데이터가 축적되고 있음
- 뉴럴네트워크를 충분히 크게 만들수록 많아지는 데이터 양의 효과를 볼 수 있음
- 즉, 모델의 성능을 높이려면 뉴럴네트워크를 크게 만들거나, (레이블이 있는) 데이터를 많이 넣어야 함
- 데이터가 많지 않을때는 전통적 ML 모델이나 딥러닝 모델이나 뭐가 더 낫다고 보기 어려움. 오히려 전통적 ML을 잘 다루면 더 나은 성능을 발휘할 수도 있음

#### Computation 속도 증가

- GPU 발전

#### Algorithms의 개선

- 보다 효율적인 활성화 함수 적용하게 되었음(예: 시그모이드 함수에서 렐루 함수로 활성화 함수를 바꿔주면, 그레디언트 소멸 문제가 해결되고 학습 속도가 매우 빨라짐)

- 신경망 학습은 반복적으로 해야 하기 때문에 학습 속도의 개선은 매우 중요한 과제임
