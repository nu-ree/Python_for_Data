# 딥러닝 2단계 - 1. Practical aspects of Deep Learning

## 1. **머신러닝 어플리케이션 설정하기**

### 1.1. **Train/Dev/Test Sets** 

- 머신러닝을 적용하는 과정은 반복적. Idea - Code - Experiment 를 반복
- 서로 다른 도메인에 공통적으로 적용되는 하나의 정답은 없음. 도메인마다 각 상황에 따라 실험을 반복해서 적절한 하이퍼파라미터를 찾을 수 있음
- 데이터는 크게 3가지로 나눌 수 있음
  - 훈련 세트
  - 개발 세트(hold-out cross validation set)
  - 테스트 세트 : 최종 모델 테스트하는 데 사용
- 전통적으로 7:3 혹은 6:2:2 가 적절한 비중이라고 보았음. 
- 하지만 빅데이터 시대에서는 개발세트, 테스트세트를 훨씬 적게 가져가는 추세. 
- **100만 데이터가 있으면,  98:1:1 정도**
- 훈련/테스트 데이터셋의 분포가 일치하지 않는 경우가 많은데, 일치할수록 성능이 좋아짐
- 테스트셋은 최종 네트워크의 성능에 대한 비편향 추정(unbiased estimate)을 얻기 위해 해보는 것. 비편향 추정이 필요 없으면 안해도 ok. 보통은 훈련/개발 세트를 훈련/테스트 셋이라고 부름. 개발 셋은 교차검증에 사용되는데이터셋이라 엄연히 테스트셋과 다른 것이지만... 

### 1.2. **Bias/Variance**

- 편향과 분산은 트레이드오프 관계
- 편향이 높다 , 분산이 높다의 의미는? 
  - 인간의 오류율이 0%라고 가정했을 때,( 베이지안 최적 오차가 0% 라는 가정)
    - 훈련 셋 오류 : 1%
      개발 셋 오류 : 11 % => "분산이 높다"
    - 훈련 셋 오류 : 15%
      개발 셋 오류 : 16 % => "편향이 높다"
    - 훈련 셋 오류 : 15%
      개발 셋 오류 : 30 % => "분산이 높다" & "편향이 높다"
    - 훈련 셋 오류 : 0.5%
      개발 셋 오류 : 1% => "분산이 낮다" & "편향이 낮다"

### 1.3. **Basic Recipe for Machine Learning**

- 머신러닝을 적용하는 과정을 알아보자 
  - 먼저 훈련 세트에 대해 잘 맞추는지(편향이 높지 않은지) 확인
    - 높다면 네트워크를 층을 깊게 만들거나 더 오래 훈련시키거나 다른 신경망 구조를 사용해보는 등 훈련 셋에 대한 편향이 낮아질 때 까지 다양한 방법 시도 & 반복
  - 편향이 낮아졌다면 분산이 어느 정도 인지 개발셋을 이용해 확인
    - 높다면 데이터를 늘리거나 정규화를 해보거나 다른 신경망 구조를 사용해보거나 시도
- 딥러닝 모델은 다른 고전적인 머신러닝 모델보다 분산과 편향이 트레이드 오프 관계인 경향이 훨씬 적음. 하나를 해결한다고 해서 다른 한쪽이 올라가지 않음.  



## 2. Regularizing your neural network

### 2.1. Regularization

- 높은 분산을 해결하는 방법

  1) 데이터 늘리기

  2) 규제

- L_2 규제

  - 기존의 비용함수 $J(w, b)$ 에 $\frac{\lambda}{2m}||w||_{2}^{2} $ 를 더해서 비용함수를 만듦
    - 여기서 $\lambda$는 **규제 매개변수(regularization parameter)**라고 함
  - 왜 w만 정규화하는가? b는 안하고? 
    - 특히 high variance 문제에서는 w가 많은 매개변수를 가짐. 
    - 반면 b는 하나의 숫자임
    - 즉, 거의 모든 매개변수는 b가 아닌 w에 걸려있음. b를 정규화 한다 한들, 하나의 매개변수에만 영향을 미치는 거여서 넣지 않는 게 일반적

- L1 규제 

  - $\frac{\lambda}{2m}|w|_{1} $ 
  - (참고: 여기서 분모의 2는 단순히 스케일링 상수임)
  - L1 규제를 사용하면 w 가 희소(sparse) 해짐(w벡터에 0이 많아진다는 뜻). 모델이 압축된다고 하기도 하지만(메모리 적게써서) 모델을 압축하겠다고 L1을 쓰는 것은 별로 도움이 되지 않음. 
  - 네워크를 훌련할 때는 L2를 많이 사용함

- $\lambda$는 언제 사용? 

  - 개발 셋 혹은 교차 검증 셋에 주로 사용. 다양한 값 시도 -> 훈련 셋에 대해 과대적합을 최소화할 수 있는 값을 찾아 설정 ==> 즉, $\lambda$도 중요한 하이퍼파라미터!
  -  파이썬에선 `lambd`로 표기할 것

-  $||w^{[l]}||^2$ 는 어떻게 계산?

  - $||w^{[l]}||^2 = \sum\limits_{i=1}^{n^{[l-1]}}\sum\limits_{j=1}^{n^{[l]}}(w_{ij}^{[l]})^{2}$
  - 프로베니우스(Frobenius) 노름라고도 부름. 행렬의 원소 제곱의 합이라는 뜻

- 이걸로 어떻게 경사하강법 구현? 

  - 정규화 없이 미분하면 : $dw^{[l]} = ( from back prop )$

  - 정규화가 들어가면? $dw^{[l]} = ( from back prop )+ \frac{\lambda}{m} w^{[l]}$

  - $\rightarrow w^{[l]}:= w^{[l]} - \alpha dw^{[l]} = w^{[l]} - \alpha[( fromback prop )+ \frac{\lambda}{m} w^{[l]}] $

    $= w^{[l]} - \alpha( from back prop )- \frac{\alpha\lambda}{m} w^{[l]}$

    $= (1 - \frac{\alpha\lambda}{m}) w^{[l]} - \alpha( from back prop )$

    : 무조건 행렬 $w^{[l]}$에서 $\frac{\alpha\lambda}{m}$만 빼주기 때문에 $w^{[l]}$ 보다 작아질 수 밖에 없음

  - 경사하강법을 적용할 때 $\alpha( from back prop )$ 만큼 줄여나가기도 하지만, $w^{[l]}$ 자체를 그대로 가져가지 않고 조금 줄여서 가져감. 그래서 L2 규제를 **가중치 감쇠(weight decay)**라고 부름

- 단점은? 

  - 람다에 많은 값을 대입해봐야하므로 컴퓨팅 리소스가 많이 필요



### **2.2. Why Regularization Reduces Overfitting**

- 규제를 한다고 오버피팅이 줄어드는 이유는? 

  -  $\lambda$ 값을 아주 크게 만들면 가중치 행렬  $w^{[l]}$ 를 0에 가깝게 설정할 수 있음(**비용함수가 커지지 않으려면, $\lambda$ 가 커진 상황을 방어하기 위해 $w$를 작게 만들게 되니까**)
  - 은닉 유닛이 0에 가까워지면 은닉 유닛의 영향력이 줄어들고, 신경망은 훨씬 작고 간단해짐(로지스틱 회귀 모형과 유사해짐)
  - 높은 분산을 가지는 모델에서 높은 편향을 가지는 모델로 조절을 할 수 있음. 그 중간의 적절하 선을 찾아내야 함

- 활성화 관점에서 생각해볼까? 

  - 활성화 함수가 $g(z) = tanh(z)$라 해보자 
    - $z = wx +b$이로 $\lambda$를 늘려서 $w$를 줄이게 되면 **$z$도 범위가 줄어듦**
    - 그럼 활성화 함수를 거친 값이 **탄젠트 함수에서 좁은 영역(0을 중심으로 선형 함수 형태를 보이는 영역)에서만 값이 왔다 갔다** 하게 되고, 활서화 함수가 선형함수에 가까워짐
    - 앞서 배웠든 모든 층의 활성화 함수가 선형함수면  전체 네트워크도 선형함수의 특징을 가지게 바뀜
    - 비선형 네트워크가 가지는 큰 분산의 문제가 줄어듦

  

### **2.3. Dropout Regularization**

- 신경망의 각 층에 대해 노드를 삭제하는 확률을 설정. 예를 들어 0.5의 확률로 노드를 삭제 / 유지 한다고 하면, 더 작고 간소환 네트워크를 만들 수 있음. 삭제할 노드는 랜덤으로 선정. 
- 훈련세트마다 버리는 은닉 유닛은 달라짐. 경사하강법의 반복마다도 서로 다른 유닛 버림
- 층이 3개인 신경망을 구현한다고 하자
  - `d3 = np.random.rand(a3.shape[0], a3.shape[1]) < keep_prop`
  - `keep_prop = 0.8`로 설정
  - `a3 = np.multiply(a3, d3)`
    - `d3` 는 `True, False`로 구현된 행렬
    - `np.multiply(A,B)` 는 두 행렬의 shape이 같아야 하며, 같은 자리에 있는 원소끼리 곱해줌
    - 반면, `np.dot(A, B)`는 두 행렬 간의 행렬곱 연산을 수행. 각각이 언제 쓰이는지 명확히 이해할 것! 
  - `a3 /= keep_prop` 해줌(**inverted dropout** 테크닉. `keep_prop`을 어떻게 설정하건 `a3`의 기대값을 동일하게 유지할 수 있게 해주는 부분. 이부분을 해줘야 테스트가 쉬워짐. 스케일링 문제가 적어져서. )

### **2.4. Understanding Dropout**

- 드롭아웃은 랜덤으로 노드를 삭제 시키기 때문에, 하나의 특성에 의존 하지 못하게 만듦으로서 가중치를 다른 곳으로 분산 시킴
- 과적합이 우려되는 층(유닛, 매개변수가 많은 층)에 대해서 `keep_prop`을 낮게 설정. 정규화 시 과적합 우려 층에 람다를 크게 잡는 것과 같음 (즉, 과적합이 우려되면은 유닛을 최대한 쳐내면서 훈련...!)
- 입력층에서는 `keep_prop = 1`로 설정하는 것이 일반적. 아무리 낮아도 0.9 정도가 적당. 
- 단점 : 
  - 교차검증 해야 할 하이퍼파라미터가 또 생김..
  - 비용함수 $J$가 잘 정의되지 않음 => 최적화 값 찾기 쉽지 않음. 어떻게 해결? 처음엔 `keep_prop = 1`로 설정해서 비용함수 값을 계산한 후, 값을 조정해가며 비용함수가 단조감소(monotonic decrease)하는지 봐야함
- 과적합이 일어나기 전에는 적용 안함. 과적합이 일어나기 쉬운 (데이터가 적은) 분야에서(예를 들면 컴퓨터 비전)는 많이 사용. 

**주의**: 

- **트레이닝과 테스팅 양쪽에서 모두 드롭아웃을 적용하는 실수를 하기 쉬움!! 트레이닝에서만 이용해야 함**
- Forward & backward 양쪽에 모두 적용해야 함
- Keep_prob로 드롭아웃 레이어를 나누어주어야 함

### **2.5. Other Regularization Methods**

- Data Augmentation

  - 가고 있는 데이터를 가지고 더 많은 훈련 데이터 만들기. 예를 들어 고양이 이미지를 옆으로 뒤집거나, 비틀거나, 점을 찍어서 다른 훈련셋을 만드는 식
  - 데이터를 싸게 얻어내는 방법
  - 숫자데이터는 꾸불꾸불하게 왜곡해서 새로운 데이터 만들 수 있음. 미묘한 왜곡이면 적당. 

- Early Stopping

  - x 축을 반복 횟수로 두고, 훈련 오차 또는 비용함수가 반복 횟수에 따라 어떻게 줄어드는지 그려볼 수 있음. 단조감소하는 형태. 

  - 조기종료에서는 개발세트의 오차도 그려줌. 그럼 어느 정도 지점에서 개발세트의 오차가 늘어나는 지점이 있음. 조기종료는 이쯤에서 모델이 잘 작동한다고 보고, 훈련을 멈춤

  - 이 방식이 왜 적절? 

    - 반복 초기에 $w$는 0에 가까움. 반복 횟수를 늘려갈수록 $w$는 커지는데, 중간 정도 크기가 되었을  모델을 훈련을 멈추는 것은, 정규화 방식과 마찬가지로 적절한 가중치를 찾으면 멈춰서 과적합을 막는 것과 비슷한 원리임

  - 단점은? 

    - 비용함수를 최적화하면서 과적합을 막기 위해 정규화, 드롭아웃 등을 해야하는데, 문제를 단순히 하기 위해서는 최적화 하는데 쓰이는 도구 따로, 과적합을 막는데 쓰는 도구 따로 적용하는것이 적절
    - 근데 조기 종료는 이 두가지를 동시에 해버림.  하나의 도구로 두가지(최적화 & 과적합 방지)를 동시에 적당히(=둘 다 제대로 못함) 하는 것. 
    - 이렇게 하나의 도구로 두 문제를 적당히 해결하는건 오히려 문제를 복잡하게 만듦




## 3. Setting Up your optimization problem

### 3.1. **Normalizing Inputs** 

- 입력값 정규화는 신경망 훈련 속도를 높이는 방법 중 하나
- 정규화란? 
  - 각 피쳐의 평균, 분산 구한 후 `x:=x-mean` , `x /= sigma` 해서 평균을 0 으로 조정하고 분산을 1로 조정
  - **테스트셋을 정규화(normalize)할 때는 훈련 셋 정규화에 사용한 분산과 평균 사용**

- 정규화한 데이터를 사용하지 않으면?  
  - 예를 들면 $x_1$ 은 1부터 1000까지의 값을 갖고, $x_2$ 는 0부터 1까지의 값을 갖는다면, 그에 상응하는 $w_1, w_2$ 역시 매우 다른 스케일의 값을 가지게 될 것.
  - 그럼 비용함수 $J(w,b)$ 의 그래프가 길쭉해짐(elongated). 원반 던지기 하는 원반처럼
  - 비용함수를 최소화하는 $w, b$ 를 찾으려면 학습률($\alpha$)를 매우 낮게 설정해야 함. 값이 왔다 갔다 하므로 여러번 학습시켜야 해서. 
- 정규화를 데이터를 사용하면? 
  - 비용함수 $J(w,b)$ 의 그래프가 반구처럼 오목해지고 symmetric 
  - 어떤 지점에서 시작하건 정규화 안한 데이터의 경우보다 큰 step으로 최적값을 찾아갈 수 있음(최적화하기 쉬워짐)

- 반드시 0부터 1사이일 필요는 없음. 
  - $x_1$ 는 0부터 1 사이로,  $x_2$ 는 1부터 2 사이,  $x_3$ -1부터 1 사이로 정규화 해도 괜찮음
  - 각 값의 범위만 유사하면 된다!



### 3.2. Vanishing / Exploding gradients

- 특히 깊은 신경망 훈련시 발생하는 문제 중 하나가 경사 소실(vanishing gradient)과 경사 폭발(exploding gradients). 훈련을 하다보면 경사가 매우 매우 커지거나 매우 매우 작아져서 훈련에 지장을 줌

- 매우 깊은 신경망을 훈련한다고 하자
  - $\hat y = w^{[l]}w^{[l-1]}...w^{[2]}w^{[1]}x$  ($g(z) = z, b^{[l]} = 0$ 이라 가정)이라고 하고, 
  - $w = 1.5E = \begin{bmatrix}1.5 & 0 \\ 0 & 1.5 \end{bmatrix}$ 라고 하면, $\hat y = w^{[l]}1.5E^{l-1}x$ 는 층이 쌓일수록($l$ 이 커질수록) 급격히 커짐
  - $w = 0.5E = \begin{bmatrix}0.5 & 0 \\ 0 & 0.5 \end{bmatrix}$ 라고 하면, $\hat y = w^{[l]}0.5E^{l-1}x$ 는 층이 쌓일수록($l$ 이 커질수록) 급격히 작아짐
  - 각각 $y=1.5^{x}$ 그래프와 $y = 0.5^{x}$를 생각해보면 될 것. 
- 즉, 신경망이 깊어지는데
  - $w^{[l]} > I$ 이면 경사 폭발 문제 발생
  - $w^{l} < I$이면 경사 소실 문제 발생
- 특히 경사 소실 문제 발생시, 경사하강이 매우 조금씩 될  것
  - 그럼 학습에 많은 시간이 소요
- **따라서 초기의 $w$ 값을 잘 설정하는 것이 중요하겠다!!**



### 3.3. Weight Initialization for Deep Networks

- 경사 소실/폭발 문제를 완전히 해결하진 못하지만 부분적으로 해결하는 방법이 초기화 값을 잘 설정하는 것
- 단일 뉴런 예제를 살펴보자
  - $z = w_1x_1 + ...+ w_nx_n$ , $g(z) = a$ 가 $\hat y$가 되는 단일 뉴런이 있다고 하자. 
  - 이 경우,  $n$이 커질수록 $w_i$는 작아지길 원함($z$ 값이 작아야하니까)
  - 어떻게 해야할까? 
    - $Var(w_i) = 1/n$ 이 되도록 $w_i$를 세팅하는 것도 한 가지 방법($n$은 뉴런에 입력되는 피쳐의 수. ReLU를 활성화 함수로 쓰면 분자 1을 2로 바꿈)
    - 실제 적용시엔 $w^{[l]}$를 `np.random.rand(shape)*np.sqrt(1/(n**(l-1)))`(ReLU 적용 시엔 `np.random.rand(shape)*np.sqrt(2/(n**(l-1)))`)
  - 입력값x의 평균이 0이고 분산은 1일때 z의 범위도 비슷해지는데, **w를 이와 같은 방법으로 설정해주면 w 값이 1보다 너무 크지도 작지도 않은 값을 가지게 되어서 급격하게 경사 소실 혹은 폭발의 문제가 발생하는 것을 방지할 수 있음(완전한 해결은 x)**
- 활성화 함수에 따라 분산값(`np.sqrt(1/(n**(l-1)))`)을 다양하게 설정 할 수 있음
  - 또 다른 하이퍼파라미터다 ㅎ 
  - 최우선으로 튜닝해야 할 하이퍼파라미터는 아니지만.. 튜닝해보니 도움이 되었음. 



### 3.4. Numerical approximation of gradients

- $f(\theta) = \theta^3$ 인 그래프가 있다고 하자. 이때, $\theta$ 를 기준으로 $\theta$ 와 $\theta - \epsilon$ 또는 $\theta + \epsilon$ 사이의 기울기를 각각 구하는면, $\frac{f(\theta) - f(\theta - \epsilon)}{\epsilon}$ 또는 $\frac{f(\theta + \epsilon) - f(\theta)}{\epsilon}$ 이다. 
- 그런데, 이렇게 각각 구하 후 더해서 구하는 것보다 $\frac{f(\theta + \epsilon) - f(\theta - \epsilon)}{2\epsilon}$   을 구하는 것이 더 정확히 $g(\theta)$(즉, $d\theta$ )를 구하는 방법이다.
- 확인해볼까? 가령, $\theta = 1, \epsilon = 0.01$ 이라고 하자.
  - $\frac{f(\theta + \epsilon) - f(\theta)}{\epsilon} = (1.01)^3 - 1^3 / 0.01 = 3.0301$
  -  $\frac{f(\theta + \epsilon) - f(\theta - \epsilon)}{2\epsilon} = \frac{(1.01)^3 - (0.99)^3}{2(0.01)}= 3.001$ 이다.
  -  $g(\theta) = 3 \theta^2 = 3$ 이다. 두 번째 식으로 구하는 방식이 오류가 0.001로 더 적음

### 3.5. Gradient Checking

- gradient checking은 시간 절약해주고 역전파 버그를 찾는데 많은 도움을 줌 

- 어떻게 하나? 

  - 모든 파라미터($W^{[L]}, b^{[L]}$)를 큰 벡터 $\theta$로 변환
  - 모든 파라미터의 미분($dW^{[L]}, db^{[L]}$)도 벡터 $d\theta$로 변환
  - 이때, $d\theta$가 $J(\theta)$의 미분값(기울기)인가? 확인하는 것이 경사 검사(gradient checking!)

- 어떻게  $J(\theta)$의  미분값을 구할까?

  - 각 파라미터($i$)에 대해 아래 값을 구함
  - $d\theta^{[i]}_{approx} = \frac{J(\theta_1, ..., \theta_i+\epsilon, ...) - J(\theta_1, ..., \theta_i-\epsilon, ...)}{2\epsilon} $ 를 구하고,
  - $d\theta^{[i]} = \frac{\delta J}{\delta\theta_i}$ 를 구해서
  - $d\theta^{[i]}_{approx} \approx d\theta^{[i]}$ 인지 확인해야 함
  - 두 벡터의 거리(유사한지) 확인하기 위해서는 유클리드 거리를 구할 수 있음
    - $\frac {||d\theta_{approx} - d\theta||_{2}}{||d\theta_{approx} ||_{2} + || d\theta||_{2} }$
    - 이 거리가 $10^{-7}$보다 작으면 잘 계산되었다고 볼 수 있음!
    - $10^{-3}$ 정도면 버그가 있다고 볼 수 있음..

  

### 3.6. **Gradient Checking Implementation Notes** 

- 경사 검사는 속도가 매우 느림. 훈련시엔 사용안하고 디버깅 할때만 이용
- 거리가 매우 크게 나오면, 각각의 컴퍼넌트($W, b$ 각각)를 파봐야 함. 어떤 층에서 문제가 생기는건지 확인. 
- 정규화 항(regularization)도 $\theta$에 들어가있으므로, 잊지 말자
- 드롭아웃을 해버리면 노드가 사라져 문제 부분을 찾기 어려우므로, 드롭아웃 끄고 경사 검사 진행
- 무작위 초기화를 해도 초반에 경사 검사가 잘되는 경우 있음. 이땐 훈련을 좀 시킨 후에, 경사 검사 다시 해보자. (가끔 있는 일이긴 함.. )

